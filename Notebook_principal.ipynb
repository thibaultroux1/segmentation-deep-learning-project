{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importations des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HY-7JNroJixC"
   },
   "source": [
    "Les classes :\n",
    "\n",
    "0. Chat\n",
    "1. Lynx\n",
    "2. Loup\n",
    "3. Coyote\n",
    "4. Jaguar\n",
    "5. Guépard\n",
    "6. Chimpanzé\n",
    "7. Orang-Outan\n",
    "8. Hamster\n",
    "9. Cochon d'Inde\n",
    "10. background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import load_data6,load_data10,load_test_data\n",
    "from utils.metrics import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from utils.affichage import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test,y_test = load_test_data()\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 4\n",
    "plt.figure()\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(x_test[index,:,:,:].astype('uint8'))\n",
    "plt.figure()\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(y_test[index,:,:,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données annotées par nous (6 classes, 311 données, environ 50 images par classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x6,y6 = load_data6()\n",
    "print(x6.shape,y6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 96\n",
    "plt.figure()\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(x6[index,:,:,:].astype('uint8'))\n",
    "plt.figure()\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(y6[index,:,:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ne garder que les données de test correspondant à nos classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_filtered = np.empty((0,64,64,11))\n",
    "indices_filtered = []\n",
    "for i in range(len(x_test)):\n",
    "    if np.max(y_test[i,:,:,[2,3,4,5,6,7]])>0:\n",
    "        y_test_filtered = np.append(y_test_filtered,np.expand_dims(y_test[i],0),0)\n",
    "        indices_filtered.append(i)\n",
    "x_test_filtered = x_test[indices_filtered]\n",
    "print(x_test_filtered.shape,y_test_filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (FACULTATIF) Load toutes les données non annotées (seulement utile pour le teacher-student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers la base de données\n",
    "path = \"./animals/unlabelled/\"\n",
    "# Indice d'ajout de données dans les variables x et y \n",
    "i = 0\n",
    "# Préparation des structures de données pour x et y\n",
    "x_unlabeled = np.zeros((50000, 64, 64, 3))\n",
    "\n",
    "# Parcours des fichiers (classés) du répertoire\n",
    "dirs = os.listdir(path)\n",
    "\n",
    "# Trier les fichiers par nom alphanumérique\n",
    "def sorted_alphanumeric(data):\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
    "    return sorted(data, key=alphanum_key)\n",
    "dirs = sorted_alphanumeric(dirs)\n",
    "\n",
    "for item in dirs:\n",
    "  # Image : on va remplir la variable x\n",
    "  # Lecture de l'image\n",
    "  img = Image.open(path + item)\n",
    "  # Remplissage de la variable x\n",
    "  x_unlabeled[i] = np.asarray(img)\n",
    "  i = i+1\n",
    "\n",
    "x_unlabeled = x_unlabeled.astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (FACULTATIF) Load certaines données non annotées mais filtrées pour nos 6 classes (seulement utile pour le teacher-student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers la base de données\n",
    "path = \"./animals/unlabelled_filtered/\"\n",
    "\n",
    "# Préparation des structures de données pour x et y\n",
    "x_unlabeled_filtered = np.empty((0, 64, 64, 3))\n",
    "\n",
    "# Parcours des fichiers (classés) du répertoire\n",
    "dirs = os.listdir(path)\n",
    "\n",
    "# Trier les fichiers par nom alphanumérique\n",
    "def sorted_alphanumeric(data):\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
    "    return sorted(data, key=alphanum_key)\n",
    "dirs = sorted_alphanumeric(dirs)\n",
    "\n",
    "for item in dirs:\n",
    "  # Image : on va remplir la variable x\n",
    "  # Lecture de l'image\n",
    "  img = Image.open(path + item)\n",
    "  # Remplissage de la variable x\n",
    "  x_unlabeled_filtered = np.append(x_unlabeled_filtered,np.expand_dims(np.asarray(img),0),axis=0)\n",
    "\n",
    "x_unlabeled_filtered = x_unlabeled_filtered.astype('uint8')\n",
    "\n",
    "print(x_unlabeled_filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseau et entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import UpSampling2D, concatenate\n",
    "from keras import models\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Input\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "l1 = 0\n",
    "l2 = 0\n",
    "\n",
    "reg = l1_l2(l1=l1,l2=l2)\n",
    "\n",
    "def create_unet(image_size=64):\n",
    "  input_layer=Input((image_size, image_size, 3))\n",
    "\n",
    "  conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=reg)(input_layer)\n",
    "  conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=reg)(conv1)\n",
    "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "  \n",
    "  conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=reg)(pool1)\n",
    "  conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=reg)(conv2)\n",
    "  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "  \n",
    "  conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=reg)(pool2)\n",
    "  conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=reg)(conv3)\n",
    "  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "  \n",
    "  conv4 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=reg)(pool3)\n",
    "  conv4 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=reg)(conv4)\n",
    "  drop4 = Dropout(0.5)(conv4)\n",
    "  pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "  conv5 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=reg)(pool4)\n",
    "  conv5 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=reg)(conv5)\n",
    "  drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "  up6 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "  merge6 = concatenate([drop4,up6], axis = 3)\n",
    "  conv6 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=reg)(merge6)\n",
    "  conv6 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "  up7 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "  merge7 = concatenate([conv3,up7], axis = 3)\n",
    "  conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=reg)(merge7)\n",
    "  conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=reg)(conv7)\n",
    "  \n",
    "  up8 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "  merge8 = concatenate([conv2,up8], axis = 3)\n",
    "  conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=reg)(merge8)\n",
    "  conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=reg)(conv8)\n",
    "\n",
    "  up9 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "  merge9 = concatenate([conv1,up9], axis = 3)\n",
    "  conv9 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=reg)(merge9)\n",
    "  conv9 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',kernel_regularizer=reg)(conv9)\n",
    "  conv10 = Conv2D(11, 1, activation = 'softmax')(conv9)\n",
    "\n",
    "\n",
    "  model = Model(input_layer, conv10)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = create_unet(image_size=64)\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (Compose, RandomBrightness, RandomContrast, RandomGamma, ShiftScaleRotate, CenterCrop, HorizontalFlip, RandomSizedCrop, Rotate, RandomScale, Resize )\n",
    "\n",
    "AUGMENTATIONS_TRAIN = Compose([\n",
    "    ShiftScaleRotate(p=0.5),\n",
    "    RandomContrast(limit=0.2, p=0.5),\n",
    "    RandomGamma(gamma_limit=(80, 120), p=0.5),\n",
    "    RandomBrightness(limit=0.2, p=0.5),\n",
    "    HorizontalFlip(p=0.5)\n",
    "])\n",
    "\n",
    "AUGMENTATIONS_TRAIN2 = Compose([\n",
    "    ShiftScaleRotate(p=1),\n",
    "    RandomContrast(limit=0.2, p=1),\n",
    "    RandomGamma(gamma_limit=(80, 120), p=1),\n",
    "    RandomBrightness(limit=0.2, p=1),\n",
    "    HorizontalFlip(p=0.5)\n",
    "])\n",
    "\n",
    "AUGMENTATIONS_TRAIN3 = Compose([\n",
    "    Rotate(45,p=1),\n",
    "    RandomScale(p=1),\n",
    "    RandomContrast(limit=0.4, p=1),\n",
    "    RandomGamma(gamma_limit=(80, 120), p=1),\n",
    "    RandomBrightness(limit=0.3, p=1),\n",
    "    HorizontalFlip(p=0.5),\n",
    "    Resize(64,64,p=1)\n",
    "])\n",
    "\n",
    "AUGMENTATIONS_TRAIN4 = Compose([\n",
    "    ShiftScaleRotate(p=0.9),\n",
    "    RandomContrast(limit=0.2, p=0.9),\n",
    "    RandomGamma(gamma_limit=(80, 120), p=0.9),\n",
    "    RandomBrightness(limit=0.2, p=0.9),\n",
    "    HorizontalFlip(p=0.5),\n",
    "    RandomSizedCrop((48,48),64,64,p=0.9),\n",
    "    Resize(64,64,p=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.data_utils import Sequence\n",
    "\n",
    "class LSPDSequence(Sequence):\n",
    "    # Initialisation de la séquence avec différents paramètres\n",
    "    def __init__(self, x_set, y_set, batch_size, augmentations,nb_augment):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.augment = augmentations\n",
    "        self.indices1 = np.arange(x_set.shape[0]) \n",
    "        np.random.shuffle(self.indices1) # Les indices permettent d'accéder\n",
    "        # aux données et sont randomisés à chaque epoch pour varier la composition\n",
    "        # des batches au cours de l'entraînement\n",
    "        self.nb_augment = nb_augment\n",
    "\n",
    "    # Fonction calculant le nombre de pas de descente du gradient par epoch\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    # Application de l'augmentation de données à chaque image du batch et aux\n",
    "    # cartes de probabilités associées\n",
    "    def apply_augmentation(self, bx, by, n):\n",
    "        \"\"\" n : number of transformations for each image in the batch\"\"\"\n",
    "        batch_x = np.zeros((n*bx.shape[0],bx.shape[1],bx.shape[2],bx.shape[3]))\n",
    "        batch_y = np.zeros((n*by.shape[0],by.shape[1],by.shape[2],by.shape[3]))\n",
    "        # Pour chaque image du batch\n",
    "        for i in range(len(bx)):\n",
    "            masks = []\n",
    "            # Les 14 masques associés à l'image sont rangés dans une liste pour \n",
    "            # pourvoir être traités par la librairie Albumentation\n",
    "            for j in range(by.shape[3]):\n",
    "                masks.append(by[i,:,:,j])\n",
    "\n",
    "            img = bx[i]\n",
    "\n",
    "            for t in range(n):\n",
    "                # Application de l'augmentation à l'image et aux masques\n",
    "                transformed = self.augment(image=img, masks=masks)\n",
    "                batch_x[n*i+t] = transformed['image']\n",
    "                batch_y_list = transformed['masks']\n",
    "\n",
    "                # Reconstitution d'un tenseur à partir des masques augmentés\n",
    "                for k in range(by.shape[3]):\n",
    "                    batch_y[n*i+t,:,:,k] = batch_y_list[k]\n",
    "\n",
    "        return batch_x/255, batch_y\n",
    "\n",
    "    # Fonction appelée à chaque nouveau batch : sélection et augmentation des données\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[self.indices1[idx * self.batch_size:(idx + 1) * self.batch_size]]\n",
    "        batch_y = self.y[self.indices1[idx * self.batch_size:(idx + 1) * self.batch_size]]\n",
    "        \n",
    "        batch_x, batch_y = self.apply_augmentation(batch_x, batch_y,self.nb_augment)\n",
    "\n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "\n",
    "    # Fonction appelée à la fin d'un epoch ; on randomise les indices d'accès aux données\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut changer le type d'augmentation en changeant le paramètre augmentations\n",
    "train_gen = LSPDSequence(x6.astype('uint8'), y6, 32, augmentations=AUGMENTATIONS_TRAIN2,nb_augment=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut exécuter cette cellule plusieurs fois pour voir les différentes augmentations\n",
    "\n",
    "%matplotlib inline\n",
    "batch_x, batch_y = train_gen.__getitem__(0)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow((255*batch_x[10]).astype('uint8'))\n",
    "plt.figure()\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(batch_y[10,:,:,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du réseau (6 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = create_unet(image_size=64)\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=3e-4) \n",
    "\n",
    "model6.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics='accuracy')\n",
    "\n",
    "# mcp_save = ModelCheckpoint('model_weights/val_loss_min2/{epoch:02d}-{val_loss:.2f}.hdf5', save_best_only=True,save_weights_only=True, monitor='val_loss', mode='min')\n",
    "mcp_save = ModelCheckpoint('model_weights/6classes_augment2_bs32_aug2.hdf5', save_best_only=True,save_weights_only=True, monitor='val_loss', mode='min')\n",
    "# mcp_save = ModelCheckpoint('model_weights/all_epochs2/{epoch:02d}.hdf5', save_best_only=False,save_weights_only=True, monitor='val_accuracy', mode='max',save_freq=20*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model6.fit(train_gen,\n",
    "          epochs=100,validation_data=(x_test_filtered/255,y_test_filtered),\n",
    "          callbacks=[mcp_save])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse de l'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_training_analysis(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (FACULTATIF) On charge les poids d'un bon entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.load_weights('model_weights/6classes_augment2_bs32_aug2_valloss0.82.hdf5')\n",
    "model6.evaluate(x6/255,y6),model6.evaluate(x_test_filtered/255,y_test_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "model6.load_weights('model_weights/6classes_augment2_bs32_aug2_valloss0.82.hdf5')\n",
    "confusion_matrix(model6,x_test_filtered,y_test_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Afficher une prédiction avec l'image et la vérité terrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# 20, 40\n",
    "model6.load_weights('model_weights/6classes_augment2_bs32_aug2_valloss0.82.hdf5')\n",
    "ind_img = 40\n",
    "ind = 6\n",
    "\n",
    "prediction = model6.predict(np.expand_dims(x_test_filtered[ind_img], axis=0))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(prediction[0,:,:,ind])\n",
    "plt.show()\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(x_test_filtered[ind_img].astype('uint8'))\n",
    "plt.show()\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(y_test_filtered[ind_img,:,:,ind])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teacher-Student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraîner les réseaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_students = 1 # nombre de students à entraîner (à chaque itération, le student devient le nouveau teacher)\n",
    "nb_new_images = 100\n",
    "\n",
    "teacher = models.load_model(\"model_weights/6classes_augment2_bs32_aug2_valloss0.82.hdf5\")\n",
    "\n",
    "for i in range(nb_students):\n",
    "\n",
    "    indices_all = np.arange(len(x_unlabeled_filtered))\n",
    "    np.random.shuffle(indices_all)\n",
    "    indices_new_images = indices_all[:nb_new_images]\n",
    "\n",
    "    x_new = x_unlabeled_filtered[indices_new_images]\n",
    "    y_new = teacher.predict(x_new)\n",
    "\n",
    "    x_mixed = np.append(x6,x_new,axis=0)\n",
    "    y_mixed = np.append(y6,y_new,axis=0)\n",
    "\n",
    "    train_gen = LSPDSequence(x_mixed.astype('uint8'), y_mixed, 32, augmentations=AUGMENTATIONS_TRAIN2,nb_augment=2)\n",
    "\n",
    "    student = create_unet(image_size=64)\n",
    "    opt = keras.optimizers.Adam(learning_rate=3e-4)\n",
    "\n",
    "    student.compile(loss='categorical_crossentropy',\n",
    "                optimizer=opt,\n",
    "                metrics='accuracy')\n",
    "\n",
    "    mcp_save = ModelCheckpoint('model_weights/.student_'+str(nb_new_images)+'_'+str(i)+'.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "    \n",
    "    history = student.fit(train_gen,\n",
    "            epochs=100,validation_data=(x_test_filtered/255,y_test_filtered),\n",
    "            callbacks=[mcp_save])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluer les performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluate = models.load_model(\"model_weights/.student1352_0.hdf5\")\n",
    "model_evaluate.evaluate(x_test_filtered/255,y_test_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "confusion_matrix(model_evaluate,x_test_filtered,y_test_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regarder des prédictions sur l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "ind_img = 26\n",
    "ind = 4\n",
    "\n",
    "prediction = model_evaluate.predict(np.expand_dims(x_test_filtered[ind_img], axis=0))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(prediction[0,:,:,ind])\n",
    "plt.show()\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(x_test_filtered[ind_img].astype('uint8'))\n",
    "plt.show()\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(y_test_filtered[ind_img,:,:,ind])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Afficher des prédictions sur les données non labellisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_img = 18848\n",
    "ind = 6\n",
    "\n",
    "prediction = model_evaluate.predict(np.expand_dims(x_unlabeled[ind_img], axis=0))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(prediction[0,:,:,ind])\n",
    "plt.show()\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(x_unlabeled[ind_img].astype('uint8'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Chargement données test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
